#---------------------------------------------
# Part 1: system basic config setting
distributed: False
device: Ascend
mode: 0  # 0: graph, 1: pynative
work_root: &work_root ./work_dir/
log_level: info
amp_level: O0

# ---------------------------------------------
# Part2: module setting
loss_manager:
#  type: fixed  # dynamic or
#  scale_sense: 1024
  loss_scaler:
    type: dynamic
  grad_clip: False

optimizer:
  type: segment_anything.optim.optimizer.AdamW
  weight_decay: 1e-4
  group_param:

  lr_scheduler:
    type: segment_anything.optim.scheduler.sam_dynamic_decay_lr
    learning_rate: 8e-6
    warmup_steps: 250
    decay_steps: [ 60000, 86666 ]
    decay_factor: 10


network:
  model:
    type: vit_b
    checkpoint: ./models/sam_vit_b-35e4849c.ckpt
    freeze:
      image_encoder: True
      prompt_encoder: True

  loss:
    type: segment_anything.modeling.loss.SAMLoss


train_loader:
  dataset:
    type: segment_anything.dataset.dataset.COCODataset
    data_dir: ./datasets/coco2017/train2017
    annotation_path: ./datasets/coco2017/annotations/instances_train2017.json
    transform_pipeline:
      - type: segment_anything.dataset.transform.ImageResizeAndPad
        target_size: 1024
      - type: segment_anything.dataset.transform.ImageNorm
        hwc2chw: True
      - type: segment_anything.dataset.transform.LabelPad
        gt_size: 20
    output_column: ['image', 'masks', 'boxes', 'valid_boxes']

  model_column: ['image', 'boxes']  # columns for model cell input
  loss_column:  ['masks', 'valid_boxes']  # columns for loss function input

  shuffle: True
  batch_size: 1
  epoch_size: 8
  drop_remainder: True
  num_workers: 2
  max_rowsize: 64  # 24M space for dataloader


eval_loader: &eval_loader
  dataset:
    type: segment_anything.dataset.dataset.COCODataset
    data_dir: ./datasets/coco2017/val2017
    annotation_path: ./datasets/coco2017/annotations/instances_val2017.json
    transform_pipeline:
      - type: segment_anything.dataset.transform.ImageResizeAndPad
        target_size: 1024
      - type: segment_anything.dataset.transform.ImageNorm
        hwc2chw: True
      - type: segment_anything.dataset.transform.LabelPad
        gt_size: 40  # for coco val, most box_per_image is less than 40
    output_column: ['image', 'masks', 'boxes', 'valid_boxes', 'origin_hw']

  model_column: &model_column [ 'image', 'boxes' ]  # columns for model cell input
  eval_column: &eval_column [ 'masks', 'valid_boxes', 'origin_hw']  # columns for evaluation, usually for metric calculation or visualization

  shuffle: True
  batch_size: 1
  drop_remainder: False
  num_workers: 2
  max_rowsize: 64  # 36M space for dataloader, increase with gt_size
  max_eval_iter: null  # the max iteration to eval, default to eval all the dataset


eval_metric: &eval_metric
  - type: segment_anything.evaluate.metrics.MaskMiou
#    - type: MaskVisualization


callback:
  - type: segment_anything.utils.callbacks.TrainStatusLog
    loss_item: ['focal_loss', 'dice_loss', 'mse_loss']  # for log
    interval: 100
  - type: segment_anything.utils.callbacks.SaveCkpt
    work_root: *work_root
    interval: 1  # in epoch
  - type: segment_anything.utils.callbacks.EvalWhileTrain
    data_loader: *eval_loader
    metric: *eval_metric
    input_column:
     - *model_column
     - *eval_column
    interval: 1  # in epoch
