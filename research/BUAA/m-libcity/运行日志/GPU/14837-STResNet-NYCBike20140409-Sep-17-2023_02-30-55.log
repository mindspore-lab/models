2023-09-17 02:30:55,166 - INFO - Log directory: /home/zhangwt/remote/M-Libcity/M_libcity/log
2023-09-17 02:30:55,166 - INFO - Begin pipeline, task=traffic_state_pred, model_name=STResNet, dataset_name=NYCBike20140409, exp_id=14837
2023-09-17 02:30:55,166 - INFO - {'task': 'traffic_state_pred', 'model': 'STResNet', 'dataset': 'NYCBike20140409', 'saved_model': True, 'train': True, 'batch_size': 64, 'dataset_class': 'STResNetDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'nb_residual_unit': 12, 'batch_norm': False, 'scaler': 'minmax11', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'external_time': True, 'max_epoch': 500, 'learner': 'adam', 'learning_rate': 0.0002, 'lr_decay': False, 'clip_grad_norm': True, 'max_grad_norm': 0.1, 'use_early_stop': True, 'patience': 50, 'cache_dataset': True, 'num_workers': 1, 'pad_with_last_sample': True, 'train_rate': 0.8, 'eval_rate': 0.1, 'input_window': 12, 'output_window': 12, 'len_closeness': 4, 'len_period': 2, 'len_trend': 0, 'interval_period': 1, 'interval_trend': 7, 'use_row_column': True, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0.0, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Polygon'], 'Polygon': {'row_id': 'num', 'column_id': 'num'}}, 'grid': {'including_types': ['state'], 'state': {'row_id': 16, 'column_id': 8, 'new_flow': 'num', 'end_flow': 'num'}}, 'data_col': ['new_flow', 'end_flow'], 'data_files': ['NYCBIKE20140409'], 'geo_file': 'NYCBIKE20140409', 'output_dim': 2, 'time_intervals': 3600, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'exp_id': 14837}
2023-09-17 02:30:55,204 - INFO - Loaded file NYCBIKE20140409.geo, num_grids=128, grid_size=(16, 8)
2023-09-17 02:30:55,206 - INFO - Generate grid rel file, shape=(128, 128)
2023-09-17 02:30:55,228 - INFO - Loading file NYCBIKE20140409.grid
2023-09-17 02:30:55,639 - INFO - Loaded file NYCBIKE20140409.grid, shape=(4392, 16, 8, 2)
2023-09-17 02:30:56,006 - INFO - Dumped 0 data.
2023-09-17 02:30:56,909 - INFO - Dataset created
2023-09-17 02:30:56,909 - INFO - x shape: (4344, 6, 16, 8, 2), y shape: (4344, 1, 16, 8, 2)
2023-09-17 02:30:56,909 - INFO - ext_x shape: (4344, 6, 33), ext_y shape: (4344, 33)
2023-09-17 02:30:56,909 - INFO - train	x: (3475, 6, 16, 8, 2), y: (3475, 1, 16, 8, 2), x_ext: (3475, 6, 33), y_ext: (3475, 33)
2023-09-17 02:30:56,909 - INFO - eval	x: (435, 6, 16, 8, 2), y: (435, 1, 16, 8, 2), x_ext: (435, 6, 33), y_ext: (435, 33)
2023-09-17 02:30:56,909 - INFO - test	x: (434, 6, 16, 8, 2), y: (434, 1, 16, 8, 2), x_ext: (434, 6, 33), y_ext: (434, 33)
2023-09-17 02:30:58,313 - INFO - Saved at /home/zhangwt/remote/M-Libcity/M_libcity/cache/dataset_cache/grid_based_NYCBike20140409_12_12_0.8_0.1_minmax11_64_True_False_False_True_True_4_2_0_1_7.npz
2023-09-17 02:30:58,322 - INFO - MinMax11Scaler max: 267.0, min: 0.0
2023-09-17 02:30:58,322 - INFO - NoneScaler
2023-09-17 02:31:01,365 - INFO - STResNet<
  (network): STResNet_model<
    (relu): ReLU<>
    (tanh): Tanh<>
    (c_way): SequentialCell<
      (conv1): Conv2d<input_channels=8, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
      (ResUnits): ResUnits<
        (residual_units): SequentialCell<
          (0): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (1): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (2): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (3): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (4): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (5): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (6): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (7): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (8): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (9): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (10): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (11): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.c_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          >
        >
      (relu): ReLU<>
      (conv2): Conv2d<input_channels=64, output_channels=2, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
      (FusionLayer): TrainableEltwiseLayer<>
      >
    (p_way): SequentialCell<
      (conv1): Conv2d<input_channels=4, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
      (ResUnits): ResUnits<
        (residual_units): SequentialCell<
          (0): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (1): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (2): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (3): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (4): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (5): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (6): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (7): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (8): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (9): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (10): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          (11): ResidualUnit<
            (bn_relu_conv1): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            (bn_relu_conv2): BnReluConv<
              (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=network.p_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>
              (relu): ReLU<>
              (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
              >
            >
          >
        >
      (relu): ReLU<>
      (conv2): Conv2d<input_channels=64, output_channels=2, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>
      (FusionLayer): TrainableEltwiseLayer<>
      >
    (external_ops): SequentialCell<
      (embd): Dense<input_channels=33, output_channels=10, has_bias=True>
      (relu1): ReLU<>
      (fc): Dense<input_channels=10, output_channels=256, has_bias=True>
      (relu2): ReLU<>
      >
    >
  >
2023-09-17 02:31:01,373 - INFO - network.c_way.conv1.weight	(64, 8, 3, 3)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.conv1.bias	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.0.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.1.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,373 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.2.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.3.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.4.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.5.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,374 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.6.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.7.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.8.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,375 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.9.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.10.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.ResUnits.residual_units.11.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.conv2.weight	(2, 64, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.conv2.bias	(2,)	True
2023-09-17 02:31:01,376 - INFO - network.c_way.FusionLayer.weights	(1, 2, 16, 8)	True
2023-09-17 02:31:01,376 - INFO - network.p_way.conv1.weight	(64, 4, 3, 3)	True
2023-09-17 02:31:01,376 - INFO - network.p_way.conv1.bias	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,376 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.0.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.1.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.2.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,377 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.3.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.4.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.5.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.6.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,378 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.7.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.8.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.9.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,379 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.10.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.gamma	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv1.bn1.beta	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv1.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv1.conv1.bias	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.gamma	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv2.bn1.beta	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv2.conv1.weight	(64, 64, 3, 3)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.ResUnits.residual_units.11.bn_relu_conv2.conv1.bias	(64,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.conv2.weight	(2, 64, 3, 3)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.conv2.bias	(2,)	True
2023-09-17 02:31:01,380 - INFO - network.p_way.FusionLayer.weights	(1, 2, 16, 8)	True
2023-09-17 02:31:01,380 - INFO - network.external_ops.embd.weight	(10, 33)	True
2023-09-17 02:31:01,380 - INFO - network.external_ops.embd.bias	(10,)	True
2023-09-17 02:31:01,380 - INFO - network.external_ops.fc.weight	(256, 10)	True
2023-09-17 02:31:01,380 - INFO - network.external_ops.fc.bias	(256,)	True
2023-09-17 02:31:01,382 - INFO - Total parameter numbers: 1791704
2023-09-17 02:31:01,382 - INFO - You select `adam` optimizer.
2023-09-17 02:31:01,914 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-09-17 02:31:01,914 - INFO - Start training ...
2023-09-17 02:31:01,915 - INFO - num_batches:54
2023-09-17 02:31:22,362 - INFO - valid loss : 9506.1884765625
2023-09-17 02:31:38,212 - INFO - valid loss : 5177.4345703125
2023-09-17 02:31:53,771 - INFO - valid loss : 3353.847412109375
2023-09-17 02:32:09,571 - INFO - valid loss : 2994.593017578125
2023-09-17 02:32:25,257 - INFO - valid loss : 2852.6484375
2023-09-17 02:32:40,923 - INFO - valid loss : 2841.960205078125
2023-09-17 02:32:56,772 - INFO - valid loss : 2825.7255859375
2023-09-17 02:33:12,385 - INFO - valid loss : 2817.368896484375
2023-09-17 02:33:28,217 - INFO - valid loss : 2815.183349609375
2023-09-17 02:33:44,243 - INFO - valid loss : 2818.002685546875
2023-09-17 02:33:59,919 - INFO - valid loss : 2804.6416015625
2023-09-17 02:34:16,057 - INFO - valid loss : 2802.849853515625
2023-09-17 02:34:31,769 - INFO - valid loss : 2812.185546875
2023-09-17 02:34:47,632 - INFO - valid loss : 2796.322509765625
2023-09-17 02:35:03,325 - INFO - valid loss : 2782.59375
2023-09-17 02:35:19,051 - INFO - valid loss : 2782.538818359375
2023-09-17 02:35:34,797 - INFO - valid loss : 2777.330078125
2023-09-17 02:35:50,446 - INFO - valid loss : 2784.741455078125
2023-09-17 02:36:06,309 - INFO - valid loss : 2783.635986328125
2023-09-17 02:36:22,244 - INFO - valid loss : 2777.924560546875
2023-09-17 02:36:37,980 - INFO - valid loss : 2764.802490234375
2023-09-17 02:36:53,818 - INFO - valid loss : 2764.892822265625
2023-09-17 02:37:09,651 - INFO - valid loss : 2760.262451171875
2023-09-17 02:37:25,398 - INFO - valid loss : 2767.618408203125
2023-09-17 02:37:41,263 - INFO - valid loss : 2756.426513671875
2023-09-17 02:37:57,013 - INFO - valid loss : 2757.7333984375
2023-09-17 02:38:12,690 - INFO - valid loss : 2790.098388671875
2023-09-17 02:38:28,370 - INFO - valid loss : 4706.98291015625
2023-09-17 02:38:44,396 - INFO - valid loss : 2871.479736328125
2023-09-17 02:39:00,020 - INFO - valid loss : 2842.542724609375
2023-09-17 02:39:16,069 - INFO - valid loss : 2813.589599609375
2023-09-17 02:39:32,218 - INFO - valid loss : 2792.662353515625
2023-09-17 02:39:47,890 - INFO - valid loss : 2604.5380859375
2023-09-17 02:40:03,660 - INFO - valid loss : 2598.3896484375
2023-09-17 02:40:19,596 - INFO - valid loss : 2598.403564453125
2023-09-17 02:40:36,140 - INFO - valid loss : 2594.192626953125
2023-09-17 02:40:52,179 - INFO - valid loss : 2593.1611328125
2023-09-17 02:41:08,110 - INFO - valid loss : 2588.38623046875
2023-09-17 02:41:23,634 - INFO - valid loss : 2588.636474609375
2023-09-17 02:41:39,269 - INFO - valid loss : 2581.09130859375
2023-09-17 02:41:54,916 - INFO - valid loss : 2578.588134765625
2023-09-17 02:42:10,861 - INFO - valid loss : 2576.181884765625
2023-09-17 02:42:26,544 - INFO - valid loss : 2575.146240234375
2023-09-17 02:42:42,185 - INFO - valid loss : 2410.411865234375
2023-09-17 02:42:58,303 - INFO - valid loss : 2384.927978515625
2023-09-17 02:43:13,979 - INFO - valid loss : 2378.43017578125
2023-09-17 02:43:29,849 - INFO - valid loss : 2375.7080078125
2023-09-17 02:43:45,893 - INFO - valid loss : 2372.363037109375
2023-09-17 02:44:01,639 - INFO - valid loss : 2368.981201171875
2023-09-17 02:44:17,146 - INFO - valid loss : 2236.746826171875
2023-09-17 02:44:33,155 - INFO - valid loss : 2203.789306640625
2023-09-17 02:44:49,330 - INFO - valid loss : 2190.962646484375
2023-09-17 02:45:05,075 - INFO - valid loss : 2173.246337890625
2023-09-17 02:45:20,654 - INFO - valid loss : 2165.754638671875
2023-09-17 02:45:36,665 - INFO - valid loss : 2129.635498046875
2023-09-17 02:45:52,478 - INFO - valid loss : 2126.6025390625
2023-09-17 02:46:08,098 - INFO - valid loss : 2124.31103515625
2023-09-17 02:46:24,039 - INFO - valid loss : 2115.155517578125
2023-09-17 02:46:39,929 - INFO - valid loss : 2110.401123046875
2023-09-17 02:46:55,687 - INFO - valid loss : 1885.3570556640625
2023-09-17 02:47:11,625 - INFO - valid loss : 1877.0439453125
2023-09-17 02:47:27,327 - INFO - valid loss : 1875.7174072265625
2023-09-17 02:47:42,801 - INFO - valid loss : 1876.0184326171875
2023-09-17 02:47:58,380 - INFO - valid loss : 1867.2587890625
2023-09-17 02:48:14,069 - INFO - valid loss : 1859.4810791015625
2023-09-17 02:48:29,995 - INFO - valid loss : 1856.9827880859375
2023-09-17 02:48:45,689 - INFO - valid loss : 1850.8856201171875
2023-09-17 02:49:01,821 - INFO - valid loss : 1847.537109375
2023-09-17 02:49:17,401 - INFO - valid loss : 1848.1295166015625
2023-09-17 02:49:32,850 - INFO - valid loss : 1845.640625
2023-09-17 02:49:48,438 - INFO - valid loss : 1841.0347900390625
2023-09-17 02:50:04,365 - INFO - valid loss : 1842.8037109375
2023-09-17 02:50:19,948 - INFO - valid loss : 1842.7994384765625
2023-09-17 02:50:35,566 - INFO - valid loss : 1839.9168701171875
2023-09-17 02:50:51,535 - INFO - valid loss : 1838.3956298828125
2023-09-17 02:51:07,725 - INFO - valid loss : 1842.1842041015625
2023-09-17 02:51:23,751 - INFO - valid loss : 1836.0333251953125
2023-09-17 02:51:39,600 - INFO - valid loss : 1836.8416748046875
2023-09-17 02:51:55,505 - INFO - valid loss : 1841.0662841796875
2023-09-17 02:52:11,290 - INFO - valid loss : 1836.8892822265625
2023-09-17 02:52:26,859 - INFO - valid loss : 1831.5228271484375
2023-09-17 02:52:42,949 - INFO - valid loss : 1825.42431640625
2023-09-17 02:52:58,604 - INFO - valid loss : 1822.8336181640625
2023-09-17 02:53:14,272 - INFO - valid loss : 1825.5198974609375
2023-09-17 02:53:29,790 - INFO - valid loss : 1822.0482177734375
2023-09-17 02:53:45,445 - INFO - valid loss : 1821.9609375
2023-09-17 02:54:01,133 - INFO - valid loss : 1832.0775146484375
2023-09-17 02:54:16,892 - INFO - valid loss : 1820.5908203125
2023-09-17 02:54:32,560 - INFO - valid loss : 1818.5030517578125
2023-09-17 02:54:48,246 - INFO - valid loss : 1816.8958740234375
2023-09-17 02:55:03,971 - INFO - valid loss : 1809.6649169921875
2023-09-17 02:55:19,541 - INFO - valid loss : 1807.6070556640625
2023-09-17 02:55:35,340 - INFO - valid loss : 1799.0225830078125
2023-09-17 02:55:51,069 - INFO - valid loss : 1799.2652587890625
2023-09-17 02:56:06,537 - INFO - valid loss : 1801.6851806640625
2023-09-17 02:56:22,279 - INFO - valid loss : 1804.748046875
2023-09-17 02:56:38,172 - INFO - valid loss : 1799.8541259765625
2023-09-17 02:56:53,718 - INFO - valid loss : 1796.8533935546875
2023-09-17 02:57:09,451 - INFO - valid loss : 1796.4794921875
2023-09-17 02:57:25,131 - INFO - valid loss : 1793.4249267578125
2023-09-17 02:57:40,954 - INFO - valid loss : 1793.7642822265625
2023-09-17 02:57:56,389 - INFO - valid loss : 1787.1365966796875
2023-09-17 02:58:12,280 - INFO - valid loss : 1785.2816162109375
2023-09-17 02:58:27,986 - INFO - valid loss : 1770.0650634765625
2023-09-17 02:58:43,732 - INFO - valid loss : 1769.2620849609375
2023-09-17 02:58:59,757 - INFO - valid loss : 1771.298828125
2023-09-17 02:59:15,489 - INFO - valid loss : 1763.5196533203125
2023-09-17 02:59:30,909 - INFO - valid loss : 1768.0545654296875
2023-09-17 02:59:46,477 - INFO - valid loss : 1772.1748046875
2023-09-17 03:00:02,109 - INFO - valid loss : 1761.1038818359375
2023-09-17 03:00:17,656 - INFO - valid loss : 1762.2247314453125
2023-09-17 03:00:33,631 - INFO - valid loss : 1761.7664794921875
2023-09-17 03:00:49,701 - INFO - valid loss : 1762.5009765625
2023-09-17 03:01:05,255 - INFO - valid loss : 1760.1619873046875
2023-09-17 03:01:20,554 - INFO - valid loss : 1769.2322998046875
2023-09-17 03:01:36,316 - INFO - valid loss : 1762.1806640625
2023-09-17 03:01:51,964 - INFO - valid loss : 1752.4910888671875
2023-09-17 03:02:07,695 - INFO - valid loss : 1753.09716796875
2023-09-17 03:02:23,156 - INFO - valid loss : 1758.9317626953125
2023-09-17 03:02:38,617 - INFO - valid loss : 1753.44873046875
2023-09-17 03:02:54,249 - INFO - valid loss : 1748.65869140625
2023-09-17 03:03:09,820 - INFO - valid loss : 1745.79052734375
2023-09-17 03:03:25,380 - INFO - valid loss : 1747.8760986328125
2023-09-17 03:03:41,150 - INFO - valid loss : 1745.1544189453125
2023-09-17 03:03:56,964 - INFO - valid loss : 1745.140625
2023-09-17 03:04:12,875 - INFO - valid loss : 1743.76025390625
2023-09-17 03:04:28,530 - INFO - valid loss : 1743.0311279296875
2023-09-17 03:04:44,175 - INFO - valid loss : 1753.1435546875
2023-09-17 03:04:59,568 - INFO - valid loss : 1741.2239990234375
2023-09-17 03:05:15,079 - INFO - valid loss : 1738.0977783203125
2023-09-17 03:05:30,386 - INFO - valid loss : 1744.6739501953125
2023-09-17 03:05:45,860 - INFO - valid loss : 1740.5399169921875
2023-09-17 03:06:01,461 - INFO - valid loss : 1739.26904296875
2023-09-17 03:06:17,509 - INFO - valid loss : 1736.4024658203125
2023-09-17 03:06:33,013 - INFO - valid loss : 1735.9808349609375
2023-09-17 03:06:48,544 - INFO - valid loss : 1733.6663818359375
2023-09-17 03:07:04,122 - INFO - valid loss : 1464.6759033203125
2023-09-17 03:07:19,774 - INFO - valid loss : 1460.3294677734375
2023-09-17 03:07:35,163 - INFO - valid loss : 1456.9937744140625
2023-09-17 03:07:50,952 - INFO - valid loss : 1457.4246826171875
2023-09-17 03:08:06,885 - INFO - valid loss : 1456.4803466796875
2023-09-17 03:08:22,265 - INFO - valid loss : 1457.3519287109375
2023-09-17 03:08:38,061 - INFO - valid loss : 1455.6827392578125
2023-09-17 03:08:53,477 - INFO - valid loss : 1456.4287109375
2023-09-17 03:09:08,850 - INFO - valid loss : 1450.36572265625
2023-09-17 03:09:24,405 - INFO - valid loss : 1446.9857177734375
2023-09-17 03:09:40,195 - INFO - valid loss : 1448.3072509765625
2023-09-17 03:09:55,438 - INFO - valid loss : 1234.3302001953125
2023-09-17 03:10:10,947 - INFO - valid loss : 1213.4610595703125
2023-09-17 03:10:26,525 - INFO - valid loss : 1210.1668701171875
2023-09-17 03:10:42,222 - INFO - valid loss : 1208.2197265625
2023-09-17 03:10:57,447 - INFO - valid loss : 1209.7152099609375
2023-09-17 03:11:12,882 - INFO - valid loss : 1205.781005859375
2023-09-17 03:11:28,338 - INFO - valid loss : 1204.298828125
2023-09-17 03:11:43,707 - INFO - valid loss : 1203.7642822265625
2023-09-17 03:11:59,209 - INFO - valid loss : 1200.8450927734375
2023-09-17 03:12:14,931 - INFO - valid loss : 1553.21630859375
2023-09-17 03:12:30,705 - INFO - valid loss : 1510.6419677734375
2023-09-17 03:12:46,387 - INFO - valid loss : 1452.4566650390625
2023-09-17 03:13:02,297 - INFO - valid loss : 1387.8759765625
2023-09-17 03:13:18,233 - INFO - valid loss : 1351.6597900390625
2023-09-17 03:13:33,946 - INFO - valid loss : 1048.8524169921875
2023-09-17 03:13:49,817 - INFO - valid loss : 1023.8432006835938
2023-09-17 03:14:05,623 - INFO - valid loss : 1019.5858764648438
2023-09-17 03:14:21,431 - INFO - valid loss : 1005.9149780273438
2023-09-17 03:14:37,226 - INFO - valid loss : 998.2334594726562
2023-09-17 03:14:52,837 - INFO - valid loss : 1004.824951171875
2023-09-17 03:15:08,479 - INFO - valid loss : 988.4132690429688
2023-09-17 03:15:24,238 - INFO - valid loss : 735.9794921875
2023-09-17 03:15:39,831 - INFO - valid loss : 698.5957641601562
2023-09-17 03:15:55,996 - INFO - valid loss : 695.1203002929688
2023-09-17 03:16:12,101 - INFO - valid loss : 700.6235961914062
2023-09-17 03:16:28,047 - INFO - valid loss : 688.7702026367188
2023-09-17 03:16:43,989 - INFO - valid loss : 679.9745483398438
2023-09-17 03:16:59,898 - INFO - valid loss : 681.0869140625
2023-09-17 03:17:15,547 - INFO - valid loss : 666.294189453125
2023-09-17 03:17:31,014 - INFO - valid loss : 657.7412109375
2023-09-17 03:17:46,668 - INFO - valid loss : 666.3258666992188
2023-09-17 03:18:02,443 - INFO - valid loss : 657.890869140625
2023-09-17 03:18:18,533 - INFO - valid loss : 654.1509399414062
2023-09-17 03:18:34,051 - INFO - valid loss : 653.3056030273438
2023-09-17 03:18:49,888 - INFO - valid loss : 652.3070678710938
2023-09-17 03:19:05,558 - INFO - valid loss : 652.5297241210938
2023-09-17 03:19:21,389 - INFO - valid loss : 651.677734375
2023-09-17 03:19:37,247 - INFO - valid loss : 651.6824340820312
2023-09-17 03:19:53,041 - INFO - valid loss : 654.1608276367188
2023-09-17 03:20:08,651 - INFO - valid loss : 659.1138916015625
2023-09-17 03:20:24,521 - INFO - valid loss : 651.0925903320312
2023-09-17 03:20:40,126 - INFO - valid loss : 646.646240234375
2023-09-17 03:20:56,036 - INFO - valid loss : 646.5009155273438
2023-09-17 03:21:12,160 - INFO - valid loss : 649.37109375
2023-09-17 03:21:27,859 - INFO - valid loss : 646.26513671875
2023-09-17 03:21:43,542 - INFO - valid loss : 656.1831665039062
2023-09-17 03:21:59,510 - INFO - valid loss : 644.5670776367188
2023-09-17 03:22:15,124 - INFO - valid loss : 644.9945068359375
2023-09-17 03:22:30,828 - INFO - valid loss : 645.6659545898438
2023-09-17 03:22:46,401 - INFO - valid loss : 647.8925170898438
2023-09-17 03:23:02,063 - INFO - valid loss : 639.6919555664062
2023-09-17 03:23:17,765 - INFO - valid loss : 638.4317626953125
2023-09-17 03:23:33,436 - INFO - valid loss : 636.7830200195312
2023-09-17 03:23:49,119 - INFO - valid loss : 638.3193359375
2023-09-17 03:24:04,684 - INFO - valid loss : 670.7803344726562
2023-09-17 03:24:20,452 - INFO - valid loss : 639.24365234375
2023-09-17 03:24:36,158 - INFO - valid loss : 638.6851806640625
2023-09-17 03:24:51,731 - INFO - valid loss : 637.9883422851562
2023-09-17 03:25:07,466 - INFO - valid loss : 639.88232421875
2023-09-17 03:25:23,341 - INFO - valid loss : 637.9880981445312
2023-09-17 03:25:38,976 - INFO - valid loss : 637.3903198242188
2023-09-17 03:25:54,370 - INFO - valid loss : 636.4163208007812
2023-09-17 03:26:10,026 - INFO - valid loss : 635.1426391601562
2023-09-17 03:26:25,613 - INFO - valid loss : 643.87890625
2023-09-17 03:26:41,546 - INFO - valid loss : 634.6167602539062
2023-09-17 03:26:57,122 - INFO - valid loss : 635.3709106445312
2023-09-17 03:27:12,944 - INFO - valid loss : 633.7615356445312
2023-09-17 03:27:28,493 - INFO - valid loss : 635.8875122070312
2023-09-17 03:27:44,142 - INFO - valid loss : 635.6246948242188
2023-09-17 03:28:00,005 - INFO - valid loss : 633.242431640625
2023-09-17 03:28:15,652 - INFO - valid loss : 483.1660461425781
2023-09-17 03:28:31,247 - INFO - valid loss : 401.5680847167969
2023-09-17 03:28:46,935 - INFO - valid loss : 386.5608825683594
2023-09-17 03:29:02,856 - INFO - valid loss : 380.3793640136719
2023-09-17 03:29:18,738 - INFO - valid loss : 376.7008361816406
2023-09-17 03:29:34,203 - INFO - valid loss : 374.9161071777344
2023-09-17 03:29:49,803 - INFO - valid loss : 373.7142639160156
2023-09-17 03:30:05,574 - INFO - valid loss : 375.150634765625
2023-09-17 03:30:21,532 - INFO - valid loss : 374.1019592285156
2023-09-17 03:30:37,467 - INFO - valid loss : 379.1994934082031
2023-09-17 03:30:53,560 - INFO - valid loss : 371.33740234375
2023-09-17 03:31:09,088 - INFO - valid loss : 372.166015625
2023-09-17 03:31:24,552 - INFO - valid loss : 374.08203125
2023-09-17 03:31:40,034 - INFO - valid loss : 369.5108947753906
2023-09-17 03:31:55,871 - INFO - valid loss : 371.4168701171875
2023-09-17 03:32:11,849 - INFO - valid loss : 369.6541748046875
2023-09-17 03:32:27,350 - INFO - valid loss : 363.4007873535156
2023-09-17 03:32:42,996 - INFO - valid loss : 360.646484375
2023-09-17 03:32:58,769 - INFO - valid loss : 371.9063415527344
2023-09-17 03:33:14,746 - INFO - valid loss : 347.0440673828125
2023-09-17 03:33:30,450 - INFO - valid loss : 343.3431701660156
2023-09-17 03:33:45,920 - INFO - valid loss : 343.5049133300781
2023-09-17 03:34:01,460 - INFO - valid loss : 343.8662414550781
2023-09-17 03:34:17,279 - INFO - valid loss : 352.3328552246094
2023-09-17 03:34:33,125 - INFO - valid loss : 336.636962890625
2023-09-17 03:34:48,850 - INFO - valid loss : 333.4091491699219
2023-09-17 03:35:04,361 - INFO - valid loss : 338.0806884765625
2023-09-17 03:35:20,064 - INFO - valid loss : 333.3794860839844
2023-09-17 03:35:35,903 - INFO - valid loss : 332.0547790527344
2023-09-17 03:35:51,720 - INFO - valid loss : 337.9378356933594
2023-09-17 03:36:07,568 - INFO - valid loss : 332.39556884765625
2023-09-17 03:36:23,172 - INFO - valid loss : 330.9819641113281
2023-09-17 03:36:38,978 - INFO - valid loss : 75.0479965209961
2023-09-17 03:36:54,675 - INFO - valid loss : 68.0629653930664
2023-09-17 03:37:10,460 - INFO - valid loss : 69.26786041259766
2023-09-17 03:37:26,334 - INFO - valid loss : 68.63265991210938
2023-09-17 03:37:41,894 - INFO - valid loss : 64.91649627685547
2023-09-17 03:37:57,772 - INFO - valid loss : 64.96587371826172
2023-09-17 03:38:13,827 - INFO - valid loss : 65.2729721069336
2023-09-17 03:38:29,591 - INFO - valid loss : 65.35852813720703
2023-09-17 03:38:45,564 - INFO - valid loss : 65.6278305053711
2023-09-17 03:39:01,923 - INFO - valid loss : 64.22669219970703
2023-09-17 03:39:17,802 - INFO - valid loss : 71.249267578125
2023-09-17 03:39:33,816 - INFO - valid loss : 63.18699645996094
2023-09-17 03:39:49,795 - INFO - valid loss : 61.35261535644531
2023-09-17 03:40:05,746 - INFO - valid loss : 63.2564582824707
2023-09-17 03:40:21,759 - INFO - valid loss : 62.68394088745117
2023-09-17 03:40:37,620 - INFO - valid loss : 62.3574104309082
2023-09-17 03:40:53,102 - INFO - valid loss : 60.98785400390625
2023-09-17 03:41:08,954 - INFO - valid loss : 60.7368049621582
2023-09-17 03:41:25,038 - INFO - valid loss : 61.5528678894043
2023-09-17 03:41:40,519 - INFO - valid loss : 63.33784484863281
2023-09-17 03:41:56,075 - INFO - valid loss : 61.45720291137695
2023-09-17 03:42:11,916 - INFO - valid loss : 61.37895202636719
2023-09-17 03:42:27,630 - INFO - valid loss : 54.5041618347168
2023-09-17 03:42:43,412 - INFO - valid loss : 54.72630310058594
2023-09-17 03:42:59,537 - INFO - valid loss : 55.5982780456543
2023-09-17 03:43:15,289 - INFO - valid loss : 54.9212646484375
2023-09-17 03:43:31,402 - INFO - valid loss : 54.85011672973633
2023-09-17 03:43:47,436 - INFO - valid loss : 53.155853271484375
2023-09-17 03:44:02,854 - INFO - valid loss : 57.16279983520508
2023-09-17 03:44:18,159 - INFO - valid loss : 53.554988861083984
2023-09-17 03:44:33,464 - INFO - valid loss : 52.92890930175781
2023-09-17 03:44:48,633 - INFO - valid loss : 53.81631851196289
2023-09-17 03:45:04,168 - INFO - valid loss : 52.597381591796875
2023-09-17 03:45:20,052 - INFO - valid loss : 55.1195068359375
2023-09-17 03:45:35,749 - INFO - valid loss : 52.98947525024414
2023-09-17 03:45:51,905 - INFO - valid loss : 53.98085021972656
2023-09-17 03:46:07,807 - INFO - valid loss : 52.45851516723633
2023-09-17 03:46:23,595 - INFO - valid loss : 52.26395034790039
2023-09-17 03:46:39,384 - INFO - valid loss : 52.981624603271484
2023-09-17 03:46:55,210 - INFO - valid loss : 49.87617874145508
2023-09-17 03:47:10,635 - INFO - valid loss : 47.315704345703125
2023-09-17 03:47:26,349 - INFO - valid loss : 48.30311584472656
2023-09-17 03:47:42,026 - INFO - valid loss : 47.4378662109375
2023-09-17 03:47:57,775 - INFO - valid loss : 46.43174362182617
2023-09-17 03:48:13,488 - INFO - valid loss : 52.45827102661133
2023-09-17 03:48:29,154 - INFO - valid loss : 46.41339111328125
2023-09-17 03:48:44,812 - INFO - valid loss : 45.91239929199219
2023-09-17 03:49:00,459 - INFO - valid loss : 47.654937744140625
2023-09-17 03:49:16,155 - INFO - valid loss : 47.13528060913086
2023-09-17 03:49:31,770 - INFO - valid loss : 45.855010986328125
2023-09-17 03:49:47,258 - INFO - valid loss : 45.2627067565918
2023-09-17 03:50:03,149 - INFO - valid loss : 46.0704231262207
2023-09-17 03:50:18,776 - INFO - valid loss : 50.38720703125
2023-09-17 03:50:34,550 - INFO - valid loss : 46.905452728271484
2023-09-17 03:50:50,376 - INFO - valid loss : 43.82708740234375
2023-09-17 03:51:05,842 - INFO - valid loss : 44.81892013549805
2023-09-17 03:51:21,418 - INFO - valid loss : 45.212005615234375
2023-09-17 03:51:37,216 - INFO - valid loss : 49.1051025390625
2023-09-17 03:51:52,920 - INFO - valid loss : 35.457027435302734
2023-09-17 03:52:08,582 - INFO - valid loss : 33.32149887084961
2023-09-17 03:52:24,392 - INFO - valid loss : 32.485015869140625
2023-09-17 03:52:40,090 - INFO - valid loss : 35.277610778808594
2023-09-17 03:52:56,005 - INFO - valid loss : 36.07683181762695
2023-09-17 03:53:11,991 - INFO - valid loss : 35.49882125854492
2023-09-17 03:53:28,124 - INFO - valid loss : 33.786415100097656
2023-09-17 03:53:44,035 - INFO - valid loss : 32.548912048339844
2023-09-17 03:54:00,110 - INFO - valid loss : 31.025588989257812
2023-09-17 03:54:16,125 - INFO - valid loss : 31.458906173706055
2023-09-17 03:54:32,001 - INFO - valid loss : 31.960386276245117
2023-09-17 03:54:48,353 - INFO - valid loss : 33.04143524169922
2023-09-17 03:55:04,053 - INFO - valid loss : 31.735755920410156
2023-09-17 03:55:20,173 - INFO - valid loss : 31.07793617248535
2023-09-17 03:55:35,915 - INFO - valid loss : 30.654542922973633
2023-09-17 03:55:51,981 - INFO - valid loss : 34.04719924926758
2023-09-17 03:56:07,757 - INFO - valid loss : 32.099918365478516
2023-09-17 03:56:23,539 - INFO - valid loss : 31.837371826171875
2023-09-17 03:56:39,056 - INFO - valid loss : 30.270811080932617
2023-09-17 03:56:54,794 - INFO - valid loss : 31.121984481811523
2023-09-17 03:57:10,401 - INFO - valid loss : 32.4280891418457
2023-09-17 03:57:25,946 - INFO - valid loss : 33.68516540527344
2023-09-17 03:57:41,618 - INFO - valid loss : 34.40470886230469
2023-09-17 03:57:57,275 - INFO - valid loss : 30.011152267456055
2023-09-17 03:58:13,395 - INFO - valid loss : 31.05665397644043
2023-09-17 03:58:29,100 - INFO - valid loss : 31.90309715270996
2023-09-17 03:58:45,443 - INFO - valid loss : 31.071556091308594
2023-09-17 03:59:01,375 - INFO - valid loss : 30.522165298461914
2023-09-17 03:59:17,175 - INFO - valid loss : 29.48267364501953
2023-09-17 03:59:32,802 - INFO - valid loss : 31.357248306274414
2023-09-17 03:59:48,573 - INFO - valid loss : 29.92630958557129
2023-09-17 04:00:04,377 - INFO - valid loss : 30.7757568359375
2023-09-17 04:00:19,938 - INFO - valid loss : 29.156953811645508
2023-09-17 04:00:36,073 - INFO - valid loss : 31.123620986938477
2023-09-17 04:00:51,814 - INFO - valid loss : 30.42070960998535
2023-09-17 04:01:07,507 - INFO - valid loss : 30.96978759765625
2023-09-17 04:01:23,386 - INFO - valid loss : 29.382904052734375
2023-09-17 04:01:39,517 - INFO - valid loss : 29.335256576538086
2023-09-17 04:01:55,556 - INFO - valid loss : 32.04988098144531
2023-09-17 04:02:11,436 - INFO - valid loss : 30.698564529418945
2023-09-17 04:02:27,598 - INFO - valid loss : 29.29816246032715
2023-09-17 04:02:43,353 - INFO - valid loss : 32.05246353149414
2023-09-17 04:02:59,214 - INFO - valid loss : 29.213401794433594
2023-09-17 04:03:15,018 - INFO - valid loss : 32.77311325073242
2023-09-17 04:03:30,572 - INFO - valid loss : 29.08704948425293
2023-09-17 04:03:46,159 - INFO - valid loss : 27.667497634887695
2023-09-17 04:04:01,604 - INFO - valid loss : 29.54827308654785
2023-09-17 04:04:17,269 - INFO - valid loss : 28.132789611816406
2023-09-17 04:04:32,890 - INFO - valid loss : 29.047483444213867
2023-09-17 04:04:48,652 - INFO - valid loss : 28.626380920410156
2023-09-17 04:05:04,124 - INFO - valid loss : 27.388269424438477
2023-09-17 04:05:19,638 - INFO - valid loss : 27.885238647460938
2023-09-17 04:05:35,501 - INFO - valid loss : 29.235870361328125
2023-09-17 04:05:50,973 - INFO - valid loss : 29.955373764038086
2023-09-17 04:06:06,730 - INFO - valid loss : 26.991775512695312
2023-09-17 04:06:22,399 - INFO - valid loss : 27.50458526611328
2023-09-17 04:06:38,003 - INFO - valid loss : 26.99683952331543
2023-09-17 04:06:53,710 - INFO - valid loss : 27.234766006469727
2023-09-17 04:07:09,966 - INFO - valid loss : 26.59454345703125
2023-09-17 04:07:25,918 - INFO - valid loss : 27.706697463989258
2023-09-17 04:07:41,607 - INFO - valid loss : 28.59635353088379
2023-09-17 04:07:57,126 - INFO - valid loss : 29.26019859313965
2023-09-17 04:08:12,852 - INFO - valid loss : 26.6821346282959
2023-09-17 04:08:28,914 - INFO - valid loss : 27.016050338745117
2023-09-17 04:08:44,774 - INFO - valid loss : 28.140785217285156
2023-09-17 04:09:00,492 - INFO - valid loss : 26.960233688354492
2023-09-17 04:09:16,526 - INFO - valid loss : 26.5246524810791
2023-09-17 04:09:32,112 - INFO - valid loss : 28.14505958557129
2023-09-17 04:09:48,099 - INFO - valid loss : 27.4683895111084
2023-09-17 04:10:03,986 - INFO - valid loss : 27.08233070373535
2023-09-17 04:10:19,711 - INFO - valid loss : 27.251998901367188
2023-09-17 04:10:35,454 - INFO - valid loss : 25.766572952270508
2023-09-17 04:10:50,951 - INFO - valid loss : 29.49251365661621
2023-09-17 04:11:06,749 - INFO - valid loss : 27.015138626098633
2023-09-17 04:11:22,478 - INFO - valid loss : 28.819211959838867
2023-09-17 04:11:38,492 - INFO - valid loss : 25.995920181274414
2023-09-17 04:11:54,115 - INFO - valid loss : 27.888769149780273
2023-09-17 04:12:10,252 - INFO - valid loss : 27.559152603149414
2023-09-17 04:12:26,156 - INFO - valid loss : 30.21073341369629
2023-09-17 04:12:42,465 - INFO - valid loss : 26.133323669433594
2023-09-17 04:12:58,284 - INFO - valid loss : 26.475189208984375
2023-09-17 04:13:14,121 - INFO - valid loss : 31.196619033813477
2023-09-17 04:13:29,824 - INFO - valid loss : 28.77537727355957
2023-09-17 04:13:45,831 - INFO - valid loss : 27.537336349487305
2023-09-17 04:14:01,735 - INFO - valid loss : 28.26534080505371
2023-09-17 04:14:17,582 - INFO - valid loss : 27.209287643432617
2023-09-17 04:14:33,593 - INFO - valid loss : 27.422021865844727
2023-09-17 04:14:49,126 - INFO - valid loss : 27.124893188476562
2023-09-17 04:15:05,139 - INFO - valid loss : 29.100685119628906
2023-09-17 04:15:21,112 - INFO - valid loss : 27.46158790588379
2023-09-17 04:15:36,826 - INFO - valid loss : 25.294164657592773
2023-09-17 04:15:52,362 - INFO - valid loss : 25.92027473449707
2023-09-17 04:16:08,149 - INFO - valid loss : 27.905029296875
2023-09-17 04:16:23,843 - INFO - valid loss : 27.059118270874023
2023-09-17 04:16:39,808 - INFO - valid loss : 26.604751586914062
2023-09-17 04:16:55,451 - INFO - valid loss : 26.641998291015625
2023-09-17 04:17:11,254 - INFO - valid loss : 25.531091690063477
2023-09-17 04:17:26,797 - INFO - valid loss : 26.837432861328125
2023-09-17 04:17:42,694 - INFO - valid loss : 26.10692024230957
2023-09-17 04:17:58,531 - INFO - valid loss : 26.4114990234375
2023-09-17 04:18:14,242 - INFO - valid loss : 26.051124572753906
2023-09-17 04:18:29,769 - INFO - valid loss : 27.725296020507812
2023-09-17 04:18:45,170 - INFO - valid loss : 25.432680130004883
2023-09-17 04:19:01,221 - INFO - valid loss : 23.458267211914062
2023-09-17 04:19:16,938 - INFO - valid loss : 24.081932067871094
2023-09-17 04:19:32,576 - INFO - valid loss : 24.04927635192871
2023-09-17 04:19:48,365 - INFO - valid loss : 23.038862228393555
2023-09-17 04:20:04,596 - INFO - valid loss : 23.571802139282227
2023-09-17 04:20:20,280 - INFO - valid loss : 23.486053466796875
2023-09-17 04:20:35,931 - INFO - valid loss : 23.605558395385742
2023-09-17 04:20:51,396 - INFO - valid loss : 23.20079803466797
2023-09-17 04:21:06,870 - INFO - valid loss : 23.387617111206055
2023-09-17 04:21:22,424 - INFO - valid loss : 24.827659606933594
2023-09-17 04:21:38,415 - INFO - valid loss : 22.911378860473633
2023-09-17 04:21:54,113 - INFO - valid loss : 22.62148094177246
2023-09-17 04:22:09,657 - INFO - valid loss : 23.577138900756836
2023-09-17 04:22:25,146 - INFO - valid loss : 23.41737937927246
2023-09-17 04:22:41,301 - INFO - valid loss : 23.037328720092773
2023-09-17 04:22:56,773 - INFO - valid loss : 23.64392852783203
2023-09-17 04:23:12,271 - INFO - valid loss : 24.703786849975586
2023-09-17 04:23:28,201 - INFO - valid loss : 25.02947235107422
2023-09-17 04:23:44,329 - INFO - valid loss : 23.116233825683594
2023-09-17 04:24:00,449 - INFO - valid loss : 23.22127342224121
2023-09-17 04:24:16,332 - INFO - valid loss : 22.926910400390625
2023-09-17 04:24:32,245 - INFO - valid loss : 22.700088500976562
2023-09-17 04:24:47,708 - INFO - valid loss : 23.78432273864746
2023-09-17 04:25:03,148 - INFO - valid loss : 23.527219772338867
2023-09-17 04:25:18,682 - INFO - valid loss : 22.586944580078125
2023-09-17 04:25:34,286 - INFO - valid loss : 22.77422523498535
2023-09-17 04:25:50,102 - INFO - valid loss : 25.0966796875
2023-09-17 04:26:05,678 - INFO - valid loss : 23.054777145385742
2023-09-17 04:26:21,227 - INFO - valid loss : 22.771432876586914
2023-09-17 04:26:37,072 - INFO - valid loss : 22.798852920532227
2023-09-17 04:26:52,970 - INFO - valid loss : 22.886247634887695
2023-09-17 04:27:09,025 - INFO - valid loss : 23.583364486694336
2023-09-17 04:27:24,798 - INFO - valid loss : 24.056577682495117
2023-09-17 04:27:40,690 - INFO - valid loss : 24.967676162719727
2023-09-17 04:27:56,463 - INFO - valid loss : 22.684473037719727
2023-09-17 04:28:12,367 - INFO - valid loss : 23.410263061523438
2023-09-17 04:28:28,065 - INFO - valid loss : 22.552833557128906
2023-09-17 04:28:44,017 - INFO - valid loss : 23.298860549926758
2023-09-17 04:28:59,846 - INFO - valid loss : 24.039175033569336
2023-09-17 04:29:15,430 - INFO - valid loss : 23.587722778320312
2023-09-17 04:29:31,167 - INFO - valid loss : 22.954330444335938
2023-09-17 04:29:47,381 - INFO - valid loss : 24.985315322875977
2023-09-17 04:30:03,136 - INFO - valid loss : 22.763948440551758
2023-09-17 04:30:19,393 - INFO - valid loss : 23.032638549804688
2023-09-17 04:30:34,941 - INFO - valid loss : 22.882680892944336
2023-09-17 04:30:50,666 - INFO - valid loss : 23.171037673950195
2023-09-17 04:31:06,472 - INFO - valid loss : 23.23592185974121
2023-09-17 04:31:22,839 - INFO - valid loss : 23.339662551879883
2023-09-17 04:31:38,384 - INFO - valid loss : 22.93444061279297
2023-09-17 04:31:53,920 - INFO - valid loss : 23.764841079711914
2023-09-17 04:32:09,553 - INFO - valid loss : 22.745620727539062
2023-09-17 04:32:25,411 - INFO - valid loss : 23.483247756958008
2023-09-17 04:32:41,359 - INFO - valid loss : 23.58835792541504
2023-09-17 04:32:57,051 - INFO - valid loss : 22.939809799194336
2023-09-17 04:33:12,987 - INFO - valid loss : 23.29949951171875
2023-09-17 04:33:29,012 - INFO - valid loss : 22.739059448242188
2023-09-17 04:33:44,694 - INFO - valid loss : 24.2020320892334
2023-09-17 04:34:00,611 - INFO - valid loss : 23.91539764404297
2023-09-17 04:34:16,876 - INFO - valid loss : 23.432687759399414
2023-09-17 04:34:32,883 - INFO - valid loss : 22.461273193359375
2023-09-17 04:34:48,594 - INFO - valid loss : 23.684326171875
2023-09-17 04:35:04,375 - INFO - valid loss : 23.79612922668457
2023-09-17 04:35:19,905 - INFO - valid loss : 22.899763107299805
2023-09-17 04:35:35,263 - INFO - valid loss : 23.6569881439209
2023-09-17 04:35:50,929 - INFO - valid loss : 22.723312377929688
2023-09-17 04:36:06,440 - INFO - valid loss : 22.923330307006836
2023-09-17 04:36:21,956 - INFO - valid loss : 22.96241569519043
2023-09-17 04:36:37,644 - INFO - valid loss : 22.52985191345215
2023-09-17 04:36:53,250 - INFO - valid loss : 22.298105239868164
2023-09-17 04:37:08,921 - INFO - valid loss : 23.4320011138916
2023-09-17 04:37:24,607 - INFO - valid loss : 23.68398094177246
2023-09-17 04:37:40,329 - INFO - valid loss : 23.12355613708496
2023-09-17 04:37:56,567 - INFO - valid loss : 23.729162216186523
2023-09-17 04:38:12,153 - INFO - valid loss : 22.915250778198242
2023-09-17 04:38:28,182 - INFO - valid loss : 23.18169593811035
2023-09-17 04:38:43,951 - INFO - valid loss : 22.534570693969727
2023-09-17 04:38:59,582 - INFO - valid loss : 22.745859146118164
2023-09-17 04:39:15,502 - INFO - valid loss : 24.94780921936035
2023-09-17 04:39:30,978 - INFO - valid loss : 22.836851119995117
2023-09-17 04:39:46,425 - INFO - valid loss : 23.8785343170166
2023-09-17 04:40:01,993 - INFO - valid loss : 23.751556396484375
2023-09-17 04:40:17,930 - INFO - valid loss : 22.45344352722168
2023-09-17 04:40:33,723 - INFO - valid loss : 23.736312866210938
2023-09-17 04:40:49,648 - INFO - valid loss : 22.545034408569336
2023-09-17 04:41:05,214 - INFO - valid loss : 22.239809036254883
2023-09-17 04:41:20,883 - INFO - valid loss : 22.314226150512695
2023-09-17 04:41:36,636 - INFO - valid loss : 22.485170364379883
2023-09-17 04:41:52,536 - INFO - valid loss : 22.840362548828125
2023-09-17 04:42:08,568 - INFO - valid loss : 23.9242000579834
2023-09-17 04:42:24,053 - INFO - valid loss : 22.7095947265625
2023-09-17 04:42:24,481 - INFO - Loaded model at /home/zhangwt/remote/M-Libcity/M_libcity/cache/14837/model_cache/STResNet_NYCBike20140409.ckpt
2023-09-17 04:42:24,779 - INFO - Start evaluating ...
2023-09-17 04:42:25,461 - INFO - Note that you select the single mode to evaluate!
2023-09-17 04:42:25,478 - INFO - Evaluate result is saved at /home/zhangwt/remote/M-Libcity/M_libcity/cache/14837/evaluate_cache/2023_09_17_04_42_25_STResNet_NYCBike20140409.csv
2023-09-17 04:42:25,486 - INFO - 
         MAE        MAPE        MSE      RMSE
1  2.4519145  0.24904248  27.562643  5.250014
