# MS-FSLHate

# 概述
本项目旨在构建一个MindSpore框架的仇恨言论检测模型，能够对用户发布的文本内容进行分类，识别是否包含仇恨、冒犯或正常言论。

# 数据集
本项目使用的数据集有HateXplain数据集和Hate Speech and Offensive Language Dataset (HSOL)数据集。
HateXplain数据集包含20,148条来自Twitter和Gab的帖子，每条帖子都从三个不同角度进行标注：基本的三类分类（仇恨、攻击性或正常）、目标社区（帖子中仇恨言论/攻击性言论的受害者社区）以及理由（标注决策所依据的帖子部分）。
HSOL数据集 是一个用于仇恨言论检测的数据集。作者从包含单词和 被互联网用户识别为仇恨言论的短语，由 Hatebase.org 汇编。他们使用 Twitter API 搜索 对于包含词典中术语的推文，从而产生来自 33,458 个 Twitter 用户的推文样本。他们提取了 每个用户的时间线，从而产生一组 8540 万条推文。他们从这个语料库中随机抽取了 25k 条包含词典术语的推文样本，并由 CrowdFlower （CF） 工作人员手动编码。员工被要求将每条推文标记为以下三类之一：仇恨言论、冒犯性但不是仇恨言论，或既不冒犯也不是仇恨言论。
# 模型架构
我们设计了一个仇恨言论检测模型，主要特点包括：
1. Prompt Embedding：引入可学习的提示向量，增强模型在短文本场景中的上下文理解能力；

2. 卷积层（CNN）：提取局部特征，捕捉短语或组合词的信息；

3. 双向LSTM：建模长距离依赖，获取文本语义的上下文信息；

4. 注意力机制：对关键信息赋予更高权重，提高模型解释性；

5. Dropout & LayerNorm：提升模型泛化能力。


# 训练流程
1. 训练框架：基于 MindSpore 实现整个训练、评估、推理流程；
2. 学习率策略：使用余弦退火衰减（cosine decay）调整学习率；
3. 梯度裁剪：控制训练稳定性，避免梯度爆炸；
4. 指标评估：用精准率、召回率、f1-score 综合评估模型性能；
5. 对抗数据增强：通过 nltk.wordnet 同义词替换策略对训练数据进行扰动，增强模型鲁棒性；如果缺少 WordNet 资源，可手动下载到对应目录。
> 🔧 如果缺少 WordNet 资源，可手动下载：

```python
import nltk

# 下载 WordNet 数据集到本地指定路径
nltk.download('wordnet', download_dir='./nltk_data')

# 添加数据路径（确保代码可以找到资源）
nltk.data.path.append('./nltk_data')