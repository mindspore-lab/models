# **RAGAT-Mind: 基于多粒度建模的谣言检测方法**

## **概述**
本项目实现了 **RAGAT-Mind** 模型，一种用于中文社交媒体谣言检测的多粒度建模方法。该模型结合了 **TextCNN** 提取局部特征、**GRU** 捕捉时序依赖、**多头自注意力**（MHA）聚合全局特征，以及 **双向图卷积网络**（BiGCN）用于结构化的词共现学习。该模型基于 **MindSpore** 深度学习框架进行实现。

## **数据集**
本模型在 **Weibo1-Rumor** 数据集上进行了评估。该数据集包含来自微博的实际社交媒体文本，总共有 3,387 条样本（1,538 条谣言和 1,849 条非谣言）。数据集被划分为训练集（80%）和测试集（20%）。预处理步骤包括分词、词汇索引化以及构建图卷积所需的邻接矩阵。

## **网络架构**
RAGAT-Mind 模型包括以下几个核心模块：
1. **TextCNN**：使用多种卷积核提取局部n-gram语义特征。
2. **GRU**：建模文本中的时序依赖，增强模型对语境变化的感知。
3. **MHA**：通过多头自注意力机制提升模型对重要语义区域的关注，增强全局语义建模。
4. **BiGCN**：通过双向图卷积网络（BiGCN）学习词共现图的结构化依赖。
5. **融合层**：将语义路径和结构路径的输出进行拼接，形成统一的特征表示，用于最终分类。

## **训练步骤**
1. **数据加载**：从指定路径加载 **Weibo1-Rumor** 数据集，并进行数据增强处理。
2. **模型训练**：使用 Adam 优化器，训练 50 个 epoch，并在每个 epoch 结束时计算训练集和验证集的评估指标，包括准确率、精确度、召回率和 F1 分数。
3. **保存训练结果**：训练过程中，所有的训练和验证指标会被记录并保存到 `training_results.txt` 文件中。

## **训练结果**
### 输出内容
每个 epoch 结束时，训练过程和验证过程的结果分别输出并保存。输出内容包括：
- **训练集**：
  - 损失值（Loss）
  - 准确率（Accuracy）
  - 精确度（Precision）
  - 召回率（Recall）
  - F1 分数（F1-Score）
  - 训练时间（Training Time）
  
- **验证集**：
  - 测试准确率（Test Accuracy）
  - 测试精确度（Test Precision）
  - 测试召回率（Test Recall）
  - 测试 F1 分数（Test F1-Score）

### 性能比较
我们与多种基线模型进行了对比实验，包括 **TextCNN**、**GRU-ATT**、**TextGCN** 和 **BERT-FT** 等。性能比较的评估指标包括准确率、精确度、召回率、宏平均F1和推理延迟时间。**RAGAT-Mind** 在准确率和宏平均F1方面显著优于所有基线模型，达到了 **99.2%** 的测试准确率和 **0.9919** 的宏平均F1分数。

---

> **注意**: 训练和测试结果将保存在 `training_results.txt` 文件中。
