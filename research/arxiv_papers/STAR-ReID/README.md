# ğŸŒŸ åŸºäºè§†é¢‘çš„è·¨æ¨¡æ€è¡Œäººé‡è¯†åˆ«çš„éª¨æ¶å¼•å¯¼æ—¶ç©ºç‰¹å¾å­¦ä¹ æ–¹æ³•

è¯¥ä»“åº“ä¸ºè®ºæ–‡ï¼šâ€œ**Skeleton-Guided Spatial-Temporal Feature Learning for Video-Based Visible-Infrared Person Re-Identification**â€ çš„ä»£ç ä»“åº“ã€‚è¯¥ç‰ˆæœ¬ä»£ç çš„æ¡†æ¶åŸºäº **MindSpore**ã€‚

![æ¡†æ¶å›¾](./Fig/framework.jpg)

ğŸ¥ **Video-based visible-infrared person re-identification (VVI-ReID)** is challenging due to significant modality feature discrepancies. Spatial-temporal information in videos is crucial, but the accuracy of spatial-temporal information is often influenced by issues like low quality and occlusions in videos. Existing methods mainly focus on reducing modality differences, but pay limited attention to improving spatial-temporal features, particularly for infrared videos.

To address this, we propose a novel **Skeleton-guided spatial-Temporal feAture leaRning (STAR)** method for VVI-ReID. By using skeleton information, which is robust to issues such as poor image quality and occlusions, STAR improves the accuracy of spatial-temporal features in videos of both modalities.

Specifically:

1. ğŸ–¼ï¸ **Frame level**: The robust structured skeleton information refines the visual features of individual frames.
2. ğŸ”„ **Sequence level**: A feature aggregation mechanism based on a skeleton key points graph learns the contribution of different body parts to spatial-temporal features, further enhancing global features.

ğŸ“Š **Experiments on benchmark datasets** demonstrate that STAR outperforms state-of-the-art methods.

---

## âš™ï¸ é…ç½®

### ç¤ºä¾‹ä»£ç 

```sh
msrun --worker_num=2 --local_worker_num=2 --master_port=8118 --log_dir=msrun_log --join=True --cluster_time_out=300 code_new/model_ms.py
```

### ç¯å¢ƒè¦æ±‚

- MindSpore >= 2.3.0
- Python >= 3.8
- Ascend: 2\*ascend-snt9b3|ARM: 48 æ ¸ 384GB

### å®‰è£…ä¾èµ–

åœ¨æœ¬ä»£ç ä¸­ä½¿ç”¨åˆ°äº†éå®˜æ–¹ç‰ˆæœ¬ einopsï¼š

```sh
pip install git+https://github.com/lvyufeng/einops
```

---

## ğŸ“‚ æ•°æ®é›†

### æ•°æ®é›†ä¸‹è½½

æˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹å…¬å¼€æ•°æ®é›†è¿›è¡Œå®éªŒï¼š

- ğŸŒŒ **SYSU-MM01**: ä¸‹è½½é“¾æ¥ [SYSU-MM01](https://github.com/link-to-sysumm01)
- ğŸ”¥ **RegDB**: ä¸‹è½½é“¾æ¥ [RegDB](https://github.com/link-to-regdb)

å°†æ•°æ®é›†ä¸‹è½½åï¼ŒæŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

````
datasets/
â”œâ”€â”€ SYSU-MM01/
â”‚   â”œâ”€â”€ visible/
â”‚   â”œâ”€â”€ infrared/
â”œâ”€â”€ RegDB/
    â”œâ”€â”€ visible/
    â”œâ”€â”€ infrared/

---

## ğŸ§ª å®éªŒè¿è¡Œ

### è®­ç»ƒ

```sh
python train.py --config config.yaml
````

### æµ‹è¯•

```sh
python test.py --model_path checkpoints/best_model.pth
```

---

## ğŸ“– å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æˆ‘ä»¬çš„ä»£ç æˆ–æ–¹æ³•ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@inproceedings{Jiang2024SkeletonGuidedSF,
  title={Skeleton-Guided Spatial-Temporal Feature Learning for Video-Based Visible-Infrared Person Re-Identification},
  author={Wenjia Jiang and Xiaoke Zhu and Jiakang Gao and Di Liao},
  year={2024},
  url={https://arxiv.org/abs/}
}
```

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ **MindSpore ç¤¾åŒº** æä¾›çš„æ”¯æŒã€‚æ›´å¤šä¿¡æ¯è¯·è®¿é—® [MindSpore å®˜ç½‘](https://www.mindspore.cn)ã€‚

---
